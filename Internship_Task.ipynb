{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd16c9f9",
   "metadata": {},
   "source": [
    "## Fraud detection model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad845751",
   "metadata": {},
   "source": [
    "## In this fraud detection model we are using amount,oldbalanceOrg,newbalanceOrig,oldbalanceDest,newbalanceDest, columns as a independent variable and isFraud column as a dependent variable.\n",
    "## So that we can perform classififcation task using support vector classifier, K nearest neighbour , random forest and logistic regression .\n",
    "## we can use the model which gives maximum accuracy.\n",
    "## The amount column is the key factor for predict fraudulent customers because we can classify the fraudulent customer on basis of the amount figure changes in his/her account. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0c17e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44e11a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =pd.read_csv(\"Fraud.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54eb8e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
       "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
       "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
       "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
       "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
       "\n",
       "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
       "0  M1979787155             0.0             0.0        0               0  \n",
       "1  M2044282225             0.0             0.0        0               0  \n",
       "2   C553264065             0.0             0.0        1               0  \n",
       "3    C38997010         21182.0             0.0        1               0  \n",
       "4  M1230701703             0.0             0.0        0               0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds=data.head()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "981eea95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   step            5 non-null      int64  \n",
      " 1   type            5 non-null      object \n",
      " 2   amount          5 non-null      float64\n",
      " 3   nameOrig        5 non-null      object \n",
      " 4   oldbalanceOrg   5 non-null      float64\n",
      " 5   newbalanceOrig  5 non-null      float64\n",
      " 6   nameDest        5 non-null      object \n",
      " 7   oldbalanceDest  5 non-null      float64\n",
      " 8   newbalanceDest  5 non-null      float64\n",
      " 9   isFraud         5 non-null      int64  \n",
      " 10  isFlaggedFraud  5 non-null      int64  \n",
      "dtypes: float64(5), int64(3), object(3)\n",
      "memory usage: 568.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16e09bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8974ad82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
       "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
       "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
       "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
       "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
       "\n",
       "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
       "0  M1979787155             0.0             0.0        0               0  \n",
       "1  M2044282225             0.0             0.0        0               0  \n",
       "2   C553264065             0.0             0.0        1               0  \n",
       "3    C38997010         21182.0             0.0        1               0  \n",
       "4  M1230701703             0.0             0.0        0               0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cded2cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "step              0\n",
       "type              0\n",
       "amount            0\n",
       "nameOrig          0\n",
       "oldbalanceOrg     0\n",
       "newbalanceOrig    0\n",
       "nameDest          0\n",
       "oldbalanceDest    0\n",
       "newbalanceDest    0\n",
       "isFraud           0\n",
       "isFlaggedFraud    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a7f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37e6c076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1=data.amount.quantile(0.25)\n",
    "#Q3=data.amount.quantile(0.75)\n",
    "#Q1,Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dec972ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IQR = Q3 - Q1\n",
    "#IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "771a1555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower_limit = Q1 - 1.5*IQR\n",
    "#upper_limit = Q3 + 1.5*IQR\n",
    "#lower_limit,upper_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37e896db",
   "metadata": {},
   "outputs": [],
   "source": [
    "##data[(data.amount<lower_limit)|(data.amount>upper_limit)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f6e08c",
   "metadata": {},
   "source": [
    "## data cleaning and getting outliers using IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cb7db86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data['amount']\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd8c4c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9e421b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.01,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.04,\n",
       " 0.06,\n",
       " 0.07,\n",
       " 0.09,\n",
       " 0.1,\n",
       " 0.11,\n",
       " 0.11,\n",
       " 0.14,\n",
       " 0.14,\n",
       " 0.15,\n",
       " 0.16,\n",
       " 0.17,\n",
       " 0.18,\n",
       " 0.18,\n",
       " 0.19,\n",
       " 0.2,\n",
       " 0.21,\n",
       " 0.22,\n",
       " 0.23,\n",
       " 0.23,\n",
       " 0.23,\n",
       " 0.23,\n",
       " 0.24,\n",
       " 0.24,\n",
       " 0.24,\n",
       " 0.26,\n",
       " 0.26,\n",
       " 0.26,\n",
       " 0.27,\n",
       " 0.28,\n",
       " 0.29,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.32,\n",
       " 0.33,\n",
       " 0.33,\n",
       " 0.33,\n",
       " 0.34,\n",
       " 0.34,\n",
       " 0.34,\n",
       " 0.35,\n",
       " 0.35,\n",
       " 0.36,\n",
       " 0.37,\n",
       " 0.37,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.41,\n",
       " 0.41,\n",
       " 0.42,\n",
       " 0.42,\n",
       " 0.43,\n",
       " 0.45,\n",
       " 0.47,\n",
       " 0.48,\n",
       " 0.5,\n",
       " 0.51,\n",
       " 0.51,\n",
       " 0.52,\n",
       " 0.52,\n",
       " 0.55,\n",
       " 0.55,\n",
       " 0.57,\n",
       " 0.58,\n",
       " 0.6,\n",
       " 0.61,\n",
       " 0.62,\n",
       " 0.63,\n",
       " 0.63,\n",
       " 0.65,\n",
       " 0.65,\n",
       " 0.67,\n",
       " 0.68,\n",
       " 0.68,\n",
       " 0.7,\n",
       " 0.7,\n",
       " 0.73,\n",
       " 0.73,\n",
       " 0.74,\n",
       " 0.74,\n",
       " 0.76,\n",
       " 0.77,\n",
       " 0.77,\n",
       " 0.78,\n",
       " 0.78,\n",
       " 0.78,\n",
       " 0.79,\n",
       " 0.79,\n",
       " 0.81,\n",
       " 0.82,\n",
       " 0.82,\n",
       " 0.87,\n",
       " 0.87,\n",
       " 0.87,\n",
       " 0.88,\n",
       " 0.89,\n",
       " 0.89,\n",
       " 0.91,\n",
       " 0.91,\n",
       " 0.91,\n",
       " 0.92,\n",
       " 0.93,\n",
       " 0.94,\n",
       " 0.96,\n",
       " 0.97,\n",
       " 0.97,\n",
       " 0.99,\n",
       " 1.0,\n",
       " 1.02,\n",
       " 1.02,\n",
       " 1.03,\n",
       " 1.03,\n",
       " 1.03,\n",
       " 1.03,\n",
       " 1.04,\n",
       " 1.04,\n",
       " 1.06,\n",
       " 1.06,\n",
       " 1.07,\n",
       " 1.08,\n",
       " 1.1,\n",
       " 1.11,\n",
       " 1.11,\n",
       " 1.11,\n",
       " 1.11,\n",
       " 1.12,\n",
       " 1.13,\n",
       " 1.13,\n",
       " 1.15,\n",
       " 1.15,\n",
       " 1.16,\n",
       " 1.16,\n",
       " 1.18,\n",
       " 1.18,\n",
       " 1.19,\n",
       " 1.24,\n",
       " 1.26,\n",
       " 1.26,\n",
       " 1.27,\n",
       " 1.27,\n",
       " 1.29,\n",
       " 1.3,\n",
       " 1.3,\n",
       " 1.31,\n",
       " 1.33,\n",
       " 1.34,\n",
       " 1.34,\n",
       " 1.35,\n",
       " 1.36,\n",
       " 1.36,\n",
       " 1.36,\n",
       " 1.37,\n",
       " 1.38,\n",
       " 1.39,\n",
       " 1.39,\n",
       " 1.39,\n",
       " 1.41,\n",
       " 1.41,\n",
       " 1.41,\n",
       " 1.41,\n",
       " 1.42,\n",
       " 1.42,\n",
       " 1.42,\n",
       " 1.43,\n",
       " 1.44,\n",
       " 1.45,\n",
       " 1.45,\n",
       " 1.47,\n",
       " 1.48,\n",
       " 1.48,\n",
       " 1.48,\n",
       " 1.51,\n",
       " 1.52,\n",
       " 1.53,\n",
       " 1.55,\n",
       " 1.55,\n",
       " 1.56,\n",
       " 1.56,\n",
       " 1.58,\n",
       " 1.59,\n",
       " 1.59,\n",
       " 1.59,\n",
       " 1.6,\n",
       " 1.6,\n",
       " 1.6,\n",
       " 1.61,\n",
       " 1.62,\n",
       " 1.62,\n",
       " 1.64,\n",
       " 1.65,\n",
       " 1.65,\n",
       " 1.66,\n",
       " 1.66,\n",
       " 1.67,\n",
       " 1.68,\n",
       " 1.69,\n",
       " 1.7,\n",
       " 1.71,\n",
       " 1.71,\n",
       " 1.71,\n",
       " 1.72,\n",
       " 1.73,\n",
       " 1.74,\n",
       " 1.76,\n",
       " 1.76,\n",
       " 1.76,\n",
       " 1.76,\n",
       " 1.77,\n",
       " 1.77,\n",
       " 1.78,\n",
       " 1.78,\n",
       " 1.78,\n",
       " 1.8,\n",
       " 1.81,\n",
       " 1.81,\n",
       " 1.81,\n",
       " 1.81,\n",
       " 1.81,\n",
       " 1.81,\n",
       " 1.83,\n",
       " 1.83,\n",
       " 1.83,\n",
       " 1.86,\n",
       " 1.87,\n",
       " 1.88,\n",
       " 1.88,\n",
       " 1.88,\n",
       " 1.89,\n",
       " 1.89,\n",
       " 1.9,\n",
       " 1.9,\n",
       " 1.91,\n",
       " 1.92,\n",
       " 1.94,\n",
       " 1.94,\n",
       " 1.95,\n",
       " 1.97,\n",
       " 1.97,\n",
       " 1.98,\n",
       " 1.98,\n",
       " 1.98,\n",
       " 1.98,\n",
       " 1.99,\n",
       " 2.0,\n",
       " 2.02,\n",
       " 2.04,\n",
       " 2.04,\n",
       " 2.05,\n",
       " 2.05,\n",
       " 2.07,\n",
       " 2.07,\n",
       " 2.09,\n",
       " 2.11,\n",
       " 2.11,\n",
       " 2.12,\n",
       " 2.12,\n",
       " 2.12,\n",
       " 2.13,\n",
       " 2.15,\n",
       " 2.15,\n",
       " 2.15,\n",
       " 2.15,\n",
       " 2.15,\n",
       " 2.15,\n",
       " 2.17,\n",
       " 2.17,\n",
       " 2.17,\n",
       " 2.17,\n",
       " 2.19,\n",
       " 2.19,\n",
       " 2.21,\n",
       " 2.23,\n",
       " 2.27,\n",
       " 2.27,\n",
       " 2.28,\n",
       " 2.29,\n",
       " 2.31,\n",
       " 2.31,\n",
       " 2.32,\n",
       " 2.32,\n",
       " 2.34,\n",
       " 2.34,\n",
       " 2.34,\n",
       " 2.35,\n",
       " 2.35,\n",
       " 2.36,\n",
       " 2.37,\n",
       " 2.39,\n",
       " 2.4,\n",
       " 2.4,\n",
       " 2.41,\n",
       " 2.42,\n",
       " 2.43,\n",
       " 2.45,\n",
       " 2.45,\n",
       " 2.45,\n",
       " 2.46,\n",
       " 2.47,\n",
       " 2.47,\n",
       " 2.47,\n",
       " 2.47,\n",
       " 2.48,\n",
       " 2.48,\n",
       " 2.48,\n",
       " 2.5,\n",
       " 2.51,\n",
       " 2.52,\n",
       " 2.53,\n",
       " 2.53,\n",
       " 2.54,\n",
       " 2.55,\n",
       " 2.57,\n",
       " 2.57,\n",
       " 2.57,\n",
       " 2.57,\n",
       " 2.58,\n",
       " 2.59,\n",
       " 2.6,\n",
       " 2.6,\n",
       " 2.61,\n",
       " 2.61,\n",
       " 2.62,\n",
       " 2.63,\n",
       " 2.65,\n",
       " 2.65,\n",
       " 2.67,\n",
       " 2.68,\n",
       " 2.69,\n",
       " 2.69,\n",
       " 2.69,\n",
       " 2.7,\n",
       " 2.7,\n",
       " 2.7,\n",
       " 2.71,\n",
       " 2.71,\n",
       " 2.71,\n",
       " 2.72,\n",
       " 2.73,\n",
       " 2.73,\n",
       " 2.73,\n",
       " 2.75,\n",
       " 2.75,\n",
       " 2.75,\n",
       " 2.76,\n",
       " 2.76,\n",
       " 2.77,\n",
       " 2.77,\n",
       " 2.78,\n",
       " 2.78,\n",
       " 2.79,\n",
       " 2.81,\n",
       " 2.82,\n",
       " 2.82,\n",
       " 2.82,\n",
       " 2.83,\n",
       " 2.83,\n",
       " 2.83,\n",
       " 2.83,\n",
       " 2.84,\n",
       " 2.84,\n",
       " 2.85,\n",
       " 2.86,\n",
       " 2.87,\n",
       " 2.88,\n",
       " 2.88,\n",
       " 2.89,\n",
       " 2.89,\n",
       " 2.9,\n",
       " 2.9,\n",
       " 2.91,\n",
       " 2.91,\n",
       " 2.93,\n",
       " 2.94,\n",
       " 2.94,\n",
       " 2.95,\n",
       " 2.96,\n",
       " 2.96,\n",
       " 2.98,\n",
       " 2.99,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.01,\n",
       " 3.01,\n",
       " 3.01,\n",
       " 3.03,\n",
       " 3.04,\n",
       " 3.04,\n",
       " 3.05,\n",
       " 3.05,\n",
       " 3.06,\n",
       " 3.06,\n",
       " 3.08,\n",
       " 3.08,\n",
       " 3.08,\n",
       " 3.1,\n",
       " 3.1,\n",
       " 3.1,\n",
       " 3.11,\n",
       " 3.13,\n",
       " 3.13,\n",
       " 3.14,\n",
       " 3.14,\n",
       " 3.15,\n",
       " 3.15,\n",
       " 3.15,\n",
       " 3.17,\n",
       " 3.17,\n",
       " 3.18,\n",
       " 3.2,\n",
       " 3.2,\n",
       " 3.2,\n",
       " 3.2,\n",
       " 3.21,\n",
       " 3.21,\n",
       " 3.22,\n",
       " 3.22,\n",
       " 3.22,\n",
       " 3.25,\n",
       " 3.25,\n",
       " 3.27,\n",
       " 3.27,\n",
       " 3.27,\n",
       " 3.28,\n",
       " 3.29,\n",
       " 3.29,\n",
       " 3.29,\n",
       " 3.3,\n",
       " 3.3,\n",
       " 3.31,\n",
       " 3.31,\n",
       " 3.31,\n",
       " 3.32,\n",
       " 3.32,\n",
       " 3.33,\n",
       " 3.35,\n",
       " 3.38,\n",
       " 3.38,\n",
       " 3.38,\n",
       " 3.38,\n",
       " 3.39,\n",
       " 3.39,\n",
       " 3.4,\n",
       " 3.41,\n",
       " 3.41,\n",
       " 3.41,\n",
       " 3.41,\n",
       " 3.41,\n",
       " 3.42,\n",
       " 3.42,\n",
       " 3.43,\n",
       " 3.44,\n",
       " 3.44,\n",
       " 3.45,\n",
       " 3.45,\n",
       " 3.45,\n",
       " 3.46,\n",
       " 3.47,\n",
       " 3.5,\n",
       " 3.5,\n",
       " 3.5,\n",
       " 3.52,\n",
       " 3.52,\n",
       " 3.52,\n",
       " 3.53,\n",
       " 3.56,\n",
       " 3.56,\n",
       " 3.57,\n",
       " 3.57,\n",
       " 3.57,\n",
       " 3.58,\n",
       " 3.59,\n",
       " 3.59,\n",
       " 3.6,\n",
       " 3.6,\n",
       " 3.6,\n",
       " 3.6,\n",
       " 3.61,\n",
       " 3.62,\n",
       " 3.62,\n",
       " 3.63,\n",
       " 3.64,\n",
       " 3.65,\n",
       " 3.65,\n",
       " 3.65,\n",
       " 3.65,\n",
       " 3.65,\n",
       " 3.66,\n",
       " 3.66,\n",
       " 3.67,\n",
       " 3.69,\n",
       " 3.7,\n",
       " 3.7,\n",
       " 3.7,\n",
       " 3.71,\n",
       " 3.71,\n",
       " 3.72,\n",
       " 3.74,\n",
       " 3.75,\n",
       " 3.76,\n",
       " 3.76,\n",
       " 3.77,\n",
       " 3.79,\n",
       " 3.81,\n",
       " 3.82,\n",
       " 3.82,\n",
       " 3.82,\n",
       " 3.83,\n",
       " 3.83,\n",
       " 3.84,\n",
       " 3.87,\n",
       " 3.87,\n",
       " 3.87,\n",
       " 3.89,\n",
       " 3.89,\n",
       " 3.9,\n",
       " 3.9,\n",
       " 3.91,\n",
       " 3.91,\n",
       " 3.91,\n",
       " 3.91,\n",
       " 3.91,\n",
       " 3.93,\n",
       " 3.93,\n",
       " 3.93,\n",
       " 3.94,\n",
       " 3.96,\n",
       " 3.97,\n",
       " 3.97,\n",
       " 3.99,\n",
       " 3.99,\n",
       " 3.99,\n",
       " 4.01,\n",
       " 4.01,\n",
       " 4.01,\n",
       " 4.02,\n",
       " 4.03,\n",
       " 4.04,\n",
       " 4.04,\n",
       " 4.05,\n",
       " 4.07,\n",
       " 4.08,\n",
       " 4.08,\n",
       " 4.08,\n",
       " 4.11,\n",
       " 4.12,\n",
       " 4.12,\n",
       " 4.12,\n",
       " 4.12,\n",
       " 4.13,\n",
       " 4.14,\n",
       " 4.14,\n",
       " 4.15,\n",
       " 4.15,\n",
       " 4.16,\n",
       " 4.17,\n",
       " 4.17,\n",
       " 4.18,\n",
       " 4.18,\n",
       " 4.19,\n",
       " 4.19,\n",
       " 4.19,\n",
       " 4.2,\n",
       " 4.21,\n",
       " 4.21,\n",
       " 4.23,\n",
       " 4.24,\n",
       " 4.26,\n",
       " 4.27,\n",
       " 4.27,\n",
       " 4.28,\n",
       " 4.28,\n",
       " 4.29,\n",
       " 4.3,\n",
       " 4.3,\n",
       " 4.31,\n",
       " 4.31,\n",
       " 4.31,\n",
       " 4.32,\n",
       " 4.32,\n",
       " 4.33,\n",
       " 4.33,\n",
       " 4.33,\n",
       " 4.35,\n",
       " 4.36,\n",
       " 4.36,\n",
       " 4.37,\n",
       " 4.39,\n",
       " 4.39,\n",
       " 4.39,\n",
       " 4.39,\n",
       " 4.4,\n",
       " 4.42,\n",
       " 4.42,\n",
       " 4.42,\n",
       " 4.42,\n",
       " 4.44,\n",
       " 4.44,\n",
       " 4.45,\n",
       " 4.45,\n",
       " 4.46,\n",
       " 4.47,\n",
       " 4.47,\n",
       " 4.48,\n",
       " 4.49,\n",
       " 4.49,\n",
       " 4.5,\n",
       " 4.54,\n",
       " 4.56,\n",
       " 4.56,\n",
       " 4.56,\n",
       " 4.56,\n",
       " 4.56,\n",
       " 4.57,\n",
       " 4.57,\n",
       " 4.57,\n",
       " 4.58,\n",
       " 4.58,\n",
       " 4.58,\n",
       " 4.62,\n",
       " 4.62,\n",
       " 4.63,\n",
       " 4.64,\n",
       " 4.66,\n",
       " 4.66,\n",
       " 4.66,\n",
       " 4.66,\n",
       " 4.68,\n",
       " 4.69,\n",
       " 4.69,\n",
       " 4.7,\n",
       " 4.71,\n",
       " 4.73,\n",
       " 4.73,\n",
       " 4.77,\n",
       " 4.78,\n",
       " 4.81,\n",
       " 4.81,\n",
       " 4.82,\n",
       " 4.82,\n",
       " 4.82,\n",
       " 4.85,\n",
       " 4.85,\n",
       " 4.87,\n",
       " 4.87,\n",
       " 4.88,\n",
       " 4.88,\n",
       " 4.9,\n",
       " 4.9,\n",
       " 4.91,\n",
       " 4.92,\n",
       " 4.92,\n",
       " 4.93,\n",
       " 4.93,\n",
       " 4.94,\n",
       " 4.95,\n",
       " 4.95,\n",
       " 4.96,\n",
       " 4.97,\n",
       " 4.97,\n",
       " 4.97,\n",
       " 4.98,\n",
       " 4.99,\n",
       " 4.99,\n",
       " 4.99,\n",
       " 4.99,\n",
       " 5.0,\n",
       " 5.01,\n",
       " 5.02,\n",
       " 5.04,\n",
       " 5.04,\n",
       " 5.04,\n",
       " 5.06,\n",
       " 5.06,\n",
       " 5.06,\n",
       " 5.07,\n",
       " 5.07,\n",
       " 5.08,\n",
       " 5.09,\n",
       " 5.09,\n",
       " 5.1,\n",
       " 5.13,\n",
       " 5.13,\n",
       " 5.13,\n",
       " 5.13,\n",
       " 5.14,\n",
       " 5.14,\n",
       " 5.15,\n",
       " 5.15,\n",
       " 5.16,\n",
       " 5.16,\n",
       " 5.16,\n",
       " 5.17,\n",
       " 5.19,\n",
       " 5.2,\n",
       " 5.2,\n",
       " 5.21,\n",
       " 5.22,\n",
       " 5.22,\n",
       " 5.23,\n",
       " 5.24,\n",
       " 5.24,\n",
       " 5.24,\n",
       " 5.25,\n",
       " 5.27,\n",
       " 5.27,\n",
       " 5.28,\n",
       " 5.28,\n",
       " 5.33,\n",
       " 5.35,\n",
       " 5.35,\n",
       " 5.35,\n",
       " 5.36,\n",
       " 5.37,\n",
       " 5.39,\n",
       " 5.39,\n",
       " 5.4,\n",
       " 5.4,\n",
       " 5.41,\n",
       " 5.42,\n",
       " 5.42,\n",
       " 5.44,\n",
       " 5.45,\n",
       " 5.46,\n",
       " 5.46,\n",
       " 5.46,\n",
       " 5.47,\n",
       " 5.47,\n",
       " 5.47,\n",
       " 5.48,\n",
       " 5.48,\n",
       " 5.48,\n",
       " 5.48,\n",
       " 5.48,\n",
       " 5.48,\n",
       " 5.49,\n",
       " 5.49,\n",
       " 5.5,\n",
       " 5.51,\n",
       " 5.54,\n",
       " 5.55,\n",
       " 5.55,\n",
       " 5.56,\n",
       " 5.56,\n",
       " 5.58,\n",
       " 5.58,\n",
       " 5.59,\n",
       " 5.59,\n",
       " 5.61,\n",
       " 5.61,\n",
       " 5.61,\n",
       " 5.62,\n",
       " 5.63,\n",
       " 5.65,\n",
       " 5.66,\n",
       " 5.66,\n",
       " 5.66,\n",
       " 5.68,\n",
       " 5.7,\n",
       " 5.71,\n",
       " 5.72,\n",
       " 5.73,\n",
       " 5.75,\n",
       " 5.75,\n",
       " 5.75,\n",
       " 5.77,\n",
       " 5.78,\n",
       " 5.8,\n",
       " 5.82,\n",
       " 5.82,\n",
       " 5.83,\n",
       " 5.83,\n",
       " 5.86,\n",
       " 5.86,\n",
       " 5.89,\n",
       " 5.89,\n",
       " 5.9,\n",
       " 5.9,\n",
       " 5.91,\n",
       " 5.92,\n",
       " 5.93,\n",
       " 5.93,\n",
       " 5.93,\n",
       " 5.94,\n",
       " 5.96,\n",
       " 5.96,\n",
       " 5.97,\n",
       " 5.97,\n",
       " 5.97,\n",
       " 5.97,\n",
       " 5.98,\n",
       " 5.99,\n",
       " 6.01,\n",
       " 6.01,\n",
       " 6.01,\n",
       " 6.04,\n",
       " 6.05,\n",
       " 6.05,\n",
       " 6.07,\n",
       " 6.08,\n",
       " 6.09,\n",
       " 6.09,\n",
       " 6.12,\n",
       " 6.12,\n",
       " 6.12,\n",
       " 6.13,\n",
       " 6.17,\n",
       " 6.17,\n",
       " 6.18,\n",
       " 6.18,\n",
       " 6.19,\n",
       " 6.2,\n",
       " 6.21,\n",
       " 6.22,\n",
       " 6.22,\n",
       " 6.26,\n",
       " 6.26,\n",
       " 6.26,\n",
       " 6.26,\n",
       " 6.27,\n",
       " 6.27,\n",
       " 6.27,\n",
       " 6.27,\n",
       " 6.27,\n",
       " 6.28,\n",
       " 6.28,\n",
       " 6.29,\n",
       " 6.29,\n",
       " 6.32,\n",
       " 6.32,\n",
       " 6.33,\n",
       " 6.33,\n",
       " 6.35,\n",
       " 6.35,\n",
       " 6.36,\n",
       " 6.36,\n",
       " 6.36,\n",
       " 6.36,\n",
       " 6.38,\n",
       " 6.39,\n",
       " 6.39,\n",
       " 6.4,\n",
       " 6.41,\n",
       " 6.41,\n",
       " 6.42,\n",
       " 6.42,\n",
       " 6.44,\n",
       " 6.45,\n",
       " 6.45,\n",
       " 6.46,\n",
       " 6.47,\n",
       " 6.47,\n",
       " 6.48,\n",
       " 6.48,\n",
       " 6.5,\n",
       " 6.5,\n",
       " 6.51,\n",
       " 6.51,\n",
       " 6.52,\n",
       " 6.52,\n",
       " 6.55,\n",
       " 6.55,\n",
       " 6.56,\n",
       " 6.57,\n",
       " 6.57,\n",
       " 6.57,\n",
       " 6.57,\n",
       " 6.57,\n",
       " 6.58,\n",
       " 6.6,\n",
       " 6.62,\n",
       " 6.62,\n",
       " 6.62,\n",
       " 6.62,\n",
       " 6.63,\n",
       " 6.63,\n",
       " 6.65,\n",
       " 6.65,\n",
       " 6.65,\n",
       " 6.67,\n",
       " 6.67,\n",
       " 6.67,\n",
       " 6.68,\n",
       " 6.69,\n",
       " 6.7,\n",
       " 6.71,\n",
       " 6.71,\n",
       " 6.73,\n",
       " 6.74,\n",
       " 6.74,\n",
       " 6.74,\n",
       " 6.75,\n",
       " 6.75,\n",
       " 6.76,\n",
       " 6.77,\n",
       " 6.78,\n",
       " 6.79,\n",
       " 6.79,\n",
       " 6.79,\n",
       " 6.79,\n",
       " 6.81,\n",
       " 6.82,\n",
       " 6.82,\n",
       " 6.83,\n",
       " 6.83,\n",
       " 6.83,\n",
       " 6.85,\n",
       " 6.85,\n",
       " 6.86,\n",
       " 6.86,\n",
       " 6.88,\n",
       " 6.88,\n",
       " 6.9,\n",
       " 6.91,\n",
       " 6.92,\n",
       " 6.93,\n",
       " 6.93,\n",
       " 6.93,\n",
       " 6.93,\n",
       " 6.93,\n",
       " 6.93,\n",
       " 6.94,\n",
       " 6.94,\n",
       " 6.94,\n",
       " 6.94,\n",
       " 6.95,\n",
       " 6.96,\n",
       " 6.96,\n",
       " 6.97,\n",
       " 6.98,\n",
       " 6.99,\n",
       " 7.0,\n",
       " 7.01,\n",
       " 7.03,\n",
       " 7.03,\n",
       " 7.04,\n",
       " 7.05,\n",
       " 7.06,\n",
       " 7.07,\n",
       " 7.07,\n",
       " 7.08,\n",
       " 7.09,\n",
       " 7.09,\n",
       " 7.1,\n",
       " 7.11,\n",
       " 7.13,\n",
       " 7.14,\n",
       " 7.15,\n",
       " 7.16,\n",
       " 7.18,\n",
       " 7.2,\n",
       " 7.21,\n",
       " 7.21,\n",
       " 7.21,\n",
       " 7.23,\n",
       " 7.25,\n",
       " 7.25,\n",
       " 7.27,\n",
       " 7.28,\n",
       " 7.32,\n",
       " 7.32,\n",
       " 7.33,\n",
       " 7.33,\n",
       " 7.33,\n",
       " 7.34,\n",
       " 7.35,\n",
       " 7.36,\n",
       " 7.36,\n",
       " 7.38,\n",
       " 7.38,\n",
       " 7.39,\n",
       " 7.4,\n",
       " 7.43,\n",
       " 7.43,\n",
       " 7.44,\n",
       " 7.45,\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=sorted(data['amount'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "052b715b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13389.57, 208721.47750000004)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1,Q3 = np.percentile(df1,[25,75])\n",
    "Q1,Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a80abca",
   "metadata": {},
   "outputs": [],
   "source": [
    "IQR = Q3-Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eebb857b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195331.90750000003"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f80eda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-279608.29125000007, 501719.3387500001)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_value =Q1-(1.5*IQR)\n",
    "upper_value = Q3 + (1.5*IQR)\n",
    "lower_value,upper_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe70b44",
   "metadata": {},
   "source": [
    "## checking multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad42145b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>step</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amount</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.689235</td>\n",
       "      <td>0.644674</td>\n",
       "      <td>-0.458707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.749066</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.689235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998210</td>\n",
       "      <td>-0.365277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.596495</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.644674</td>\n",
       "      <td>0.998210</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.347543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.567535</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.458707</td>\n",
       "      <td>-0.365277</td>\n",
       "      <td>-0.347543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612372</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newbalanceDest</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isFraud</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.749066</td>\n",
       "      <td>-0.596495</td>\n",
       "      <td>-0.567535</td>\n",
       "      <td>0.612372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                step    amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
       "step             NaN       NaN            NaN             NaN             NaN   \n",
       "amount           NaN  1.000000       0.689235        0.644674       -0.458707   \n",
       "oldbalanceOrg    NaN  0.689235       1.000000        0.998210       -0.365277   \n",
       "newbalanceOrig   NaN  0.644674       0.998210        1.000000       -0.347543   \n",
       "oldbalanceDest   NaN -0.458707      -0.365277       -0.347543        1.000000   \n",
       "newbalanceDest   NaN       NaN            NaN             NaN             NaN   \n",
       "isFraud          NaN -0.749066      -0.596495       -0.567535        0.612372   \n",
       "isFlaggedFraud   NaN       NaN            NaN             NaN             NaN   \n",
       "\n",
       "                newbalanceDest   isFraud  isFlaggedFraud  \n",
       "step                       NaN       NaN             NaN  \n",
       "amount                     NaN -0.749066             NaN  \n",
       "oldbalanceOrg              NaN -0.596495             NaN  \n",
       "newbalanceOrig             NaN -0.567535             NaN  \n",
       "oldbalanceDest             NaN  0.612372             NaN  \n",
       "newbalanceDest             NaN       NaN             NaN  \n",
       "isFraud                    NaN  1.000000             NaN  \n",
       "isFlaggedFraud             NaN       NaN             NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93fdad7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.00</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.00</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.00</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>9</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1322.91</td>\n",
       "      <td>C1402545110</td>\n",
       "      <td>1208457.61</td>\n",
       "      <td>1207134.71</td>\n",
       "      <td>M578074960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>9</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>6900.48</td>\n",
       "      <td>C517372485</td>\n",
       "      <td>1207134.71</td>\n",
       "      <td>1200234.22</td>\n",
       "      <td>M1854114037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>9</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>17399.12</td>\n",
       "      <td>C1948160352</td>\n",
       "      <td>1200234.22</td>\n",
       "      <td>1182835.10</td>\n",
       "      <td>M1940330634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>9</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>5485.20</td>\n",
       "      <td>C1586381033</td>\n",
       "      <td>1182835.10</td>\n",
       "      <td>1177349.90</td>\n",
       "      <td>M741912557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>9</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>629.44</td>\n",
       "      <td>C741191323</td>\n",
       "      <td>1177349.90</td>\n",
       "      <td>1176720.46</td>\n",
       "      <td>M1728418012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "0         1   PAYMENT   9839.64  C1231006815      170136.00       160296.36   \n",
       "1         1   PAYMENT   1864.28  C1666544295       21249.00        19384.72   \n",
       "2         1  TRANSFER    181.00  C1305486145         181.00            0.00   \n",
       "3         1  CASH_OUT    181.00   C840083671         181.00            0.00   \n",
       "4         1   PAYMENT  11668.14  C2048537720       41554.00        29885.86   \n",
       "...     ...       ...       ...          ...            ...             ...   \n",
       "49995     9   PAYMENT   1322.91  C1402545110     1208457.61      1207134.71   \n",
       "49996     9   PAYMENT   6900.48   C517372485     1207134.71      1200234.22   \n",
       "49997     9   PAYMENT  17399.12  C1948160352     1200234.22      1182835.10   \n",
       "49998     9   PAYMENT   5485.20  C1586381033     1182835.10      1177349.90   \n",
       "49999     9   PAYMENT    629.44   C741191323     1177349.90      1176720.46   \n",
       "\n",
       "          nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
       "0      M1979787155             0.0             0.0        0               0  \n",
       "1      M2044282225             0.0             0.0        0               0  \n",
       "2       C553264065             0.0             0.0        1               0  \n",
       "3        C38997010         21182.0             0.0        1               0  \n",
       "4      M1230701703             0.0             0.0        0               0  \n",
       "...            ...             ...             ...      ...             ...  \n",
       "49995   M578074960             0.0             0.0        0               0  \n",
       "49996  M1854114037             0.0             0.0        0               0  \n",
       "49997  M1940330634             0.0             0.0        0               0  \n",
       "49998   M741912557             0.0             0.0        0               0  \n",
       "49999  M1728418012             0.0             0.0        0               0  \n",
       "\n",
       "[50000 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4=data.head(50000)\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3404b3a",
   "metadata": {},
   "source": [
    "# Implementation of Support vector classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17fd81da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df4[['amount', 'oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest']]\n",
    "y= df4[['isFraud']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30840ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2033b41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c796ab7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pravin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(random_state=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca2cbc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24d8bf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14974     0]\n",
      " [   26     0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9982666666666666"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bc40fe",
   "metadata": {},
   "source": [
    "### Fraud detection model using Support Vector Classifier gives us 99% of accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067a4515",
   "metadata": {},
   "source": [
    "# Implementation of random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ac6bdef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = x.describe()\n",
    "#df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a02f0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35c62774",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df4[['amount', 'oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest']]\n",
    "y= df4[['isFraud']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "36f2a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6b8c217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "12f91f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-ea2c99e4aedb>:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regressor.fit(X_train, y_train)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "353b853f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14974     0]\n",
      " [   26     0]]\n",
      "0.9982666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     14974\n",
      "           1       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           1.00     15000\n",
      "   macro avg       0.50      0.50      0.50     15000\n",
      "weighted avg       1.00      1.00      1.00     15000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pravin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Pravin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Pravin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Pravin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Pravin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Pravin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "#print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "cr = (classification_report(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3e0bf4",
   "metadata": {},
   "source": [
    "## fraud detection model using Random Forest algorithm for classification gives 99% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a95547a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88d446d0",
   "metadata": {},
   "source": [
    "# Implementation of knn classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8eb3aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d96b25ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df4[['amount', 'oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest']]\n",
    "y = df4[['isFraud']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cf4eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "             X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd776850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pravin\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b648eb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(knn.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0d23c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pravin\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)\n",
    " \n",
    "# Calculate the accuracy of the model\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b04c4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90c030f7",
   "metadata": {},
   "source": [
    "## Fraud detection model using K nearest neighbour gives us 99% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df4220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6e39d99",
   "metadata": {},
   "source": [
    "# Implementation of Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1be15ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a62ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df4[['amount', 'oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest']]\n",
    "y = df4[['isFraud']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfaeb2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55cd74b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e890a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19998f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pravin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5dc9c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6f63671",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0645059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = (metrics.confusion_matrix(y_test, y_pred))\n",
    "#print(\" Confusion Matrix:\\n\\n cm:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfd5aa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9980\n",
      "           1       0.40      0.80      0.53        20\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       0.70      0.90      0.77     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60b1006d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 1.0\n"
     ]
    }
   ],
   "source": [
    "a= (metrics.accuracy_score(y_test, y_pred))\n",
    "print( \"Accuracy score:\",round(a,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f38cd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "382c7518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e49d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "242f424d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roc Curve evaluation\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Roc Curve evaluation\")\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "plt.plot(fpr,tpr,label=\"data, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944803f6",
   "metadata": {},
   "source": [
    "## Logistic regression gives max 100% accuracy for fraud detection so it is preferable for detecting the frauds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d42f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dbcc44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8facd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
